{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching the location of each TCR to contracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first start by reading the cleaned and matched TCRs for 2024 which are matched with contracts number. As well as Karins matching between bandel and number of hours of servicefönster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Förbindelser and BIS (for mapping Bandelnr <-> Kontrakt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Excel file containing the dictionary for bandel matching, and keep only relevant columns and bandel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'BIS-data 2024-01-09 - Bandel, plats och förbindelselinje, alla spår.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m dictionary_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBIS-data 2024-01-09 - Bandel, plats och förbindelselinje, alla spår.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Read the entire dictionary into a DataFrame\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m dictionary_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictionary_file_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'BIS-data 2024-01-09 - Bandel, plats och förbindelselinje, alla spår.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Update: the new file includes spårnummer and type of track\n",
    "dictionary_file_path = \"BIS-data 2024-01-09 - Bandel, plats och förbindelselinje, alla spår.xlsx\"\n",
    "\n",
    "# Read the entire dictionary into a DataFrame\n",
    "dictionary_df = pd.read_excel(dictionary_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on the main tracks\n",
    "# keep only rows where column Spår_huvud_sido is nhsp\n",
    "main_tracks_df = dictionary_df[dictionary_df[\"Spår_huvud_sido\"] == \"nhsp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Group by 'BdlNr', 'Bandel', 'Plats_sign', 'Plats' and sum 'Banlangd'\n",
    "grouped_by_plats = main_tracks_df.groupby(['BdlNr', 'Bandel', 'Plats_sign', 'Plats'])['Banlangd'].sum().reset_index()\n",
    "\n",
    "# Step 2: Group by 'BdlNr', 'Bandel', 'Forbind' and sum 'Banlangd'\n",
    "grouped_by_forbind = main_tracks_df.groupby(['BdlNr', 'Bandel', 'Forbind'])['Banlangd'].sum().reset_index()\n",
    "\n",
    "# Step 3: Add 'Plats_sign' and 'Plats' columns with NaN to 'grouped_by_forbind' for consistency\n",
    "grouped_by_forbind['Plats_sign'] = pd.NA\n",
    "grouped_by_forbind['Plats'] = pd.NA\n",
    "\n",
    "# Step 4: Add 'Forbind' column with NaN to 'grouped_by_plats' for consistency\n",
    "grouped_by_plats['Forbind'] = pd.NA\n",
    "\n",
    "# Step 5: Combine the two DataFrames using outer concatenation\n",
    "combined_df = pd.concat([grouped_by_plats, grouped_by_forbind], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandelar from contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the Excel file containing service contracts for each bandel\n",
    "#excel_file_path = \"servicekontrakt_per_bandel_Abdou.xlsx\"\n",
    "excel_file_path = \"more_servicekontrakt_per_bandel.xlsx\"\n",
    "\n",
    "#sheet_name = \"uppdaterad\"\n",
    "sheet_name = \"tid per bandel\"\n",
    "\n",
    "# Read the specific sheet 'T24' into a DataFrame\n",
    "servicekontrakt_df = pd.read_excel(excel_file_path, sheet_name=sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching TCR:s Förbindelser with bandelar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There some rows where the bandel is not identified because the Från trafikplats is not in the dictionary. For these rows we will use the bandel that is identified in related row, i.e., rows with the same TCR-id and with Platssekvensnummer which is neighboring (i.e., Platssekvensnummer = Platssekvensnummer of the unidentified bandel row minus or plus 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by TCR-id and Starttid\n",
    "def get_first_last_rows(group):\n",
    "    # Get min and max Platssekvensnummer rows\n",
    "    first_row = group[group['Platssekvensnummer'] == group['Platssekvensnummer'].min()]\n",
    "    last_row = group[group['Platssekvensnummer'] == group['Platssekvensnummer'].max()]\n",
    "    return pd.concat([first_row, last_row])\n",
    "\n",
    "# Apply the function to each group\n",
    "filtered_tcr_df = tcr_df.groupby(['TCR-id', 'Starttid'], as_index=False).apply(get_first_last_rows)\n",
    "\n",
    "# Reset index if needed\n",
    "filtered_tcr_df = filtered_tcr_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before calculating the length between two consecutive places/rows, we need to reformat the tcr_df so that in each row we combine the row with the next row (in Platssekvensnummer), if any (until final row in the sequence).  We create a new column called förbind_list which will contactenate Från trafikplats of two consecutive rows, e.g., A-B (where A is trafikplats of the first row and B is the second), next row will have B-C, etc. until the final förbind in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Sort the DataFrame by 'TCR-id' and 'Platssekvensnummer'\n",
    "filtered_tcr_df = filtered_tcr_df.sort_values(by=['TCR-id', 'Starttid', 'Platssekvensnummer']).reset_index(drop=True)\n",
    "\n",
    "# Step 4: Create 'next_trafikplats' and 'next_Från_inkluderad'\n",
    "filtered_tcr_df['next_trafikplats'] = filtered_tcr_df.groupby(['TCR-id', 'Starttid'])['Från trafikplats'].shift(-1)\n",
    "filtered_tcr_df['next_Från_inkluderad'] = filtered_tcr_df.groupby(['TCR-id', 'Starttid'])['Från inkluderad'].shift(-1)\n",
    "\n",
    "# Step 5: Create 'förbind_list' with conditional parentheses\n",
    "def format_trafikplats(trafikplats, inkluderad):\n",
    "    \"\"\"Format trafikplats name with parentheses based on inclusion status.\"\"\"\n",
    "    if inkluderad != 'Helt':\n",
    "        return f\"({trafikplats})\"\n",
    "    return trafikplats\n",
    "\n",
    "def create_förbind(row):\n",
    "    \"\"\"Create förbind string for a row, connecting two trafikplats names.\"\"\"\n",
    "    if pd.isna(row['next_trafikplats']):\n",
    "        return None\n",
    "\n",
    "    if(row['Från trafikplats'] == row['next_trafikplats']):\n",
    "        return f\"{row['Från trafikplats']}\"\n",
    "\n",
    "    from_tp = format_trafikplats(row['Från trafikplats'], row['Från inkluderad'])\n",
    "    to_tp = format_trafikplats(row['next_trafikplats'], row['next_Från_inkluderad'])\n",
    "\n",
    "\n",
    "    return f\"{from_tp}-{to_tp}\"\n",
    "\n",
    "# Apply the function to create förbind_list\n",
    "filtered_tcr_df['förbind_list'] = filtered_tcr_df.apply(create_förbind, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Remove temporary 'next_trafikplats' and 'next_Från_inkluderad' columns\n",
    "#filtered_tcr_df = filtered_tcr_df.drop(columns=['next_trafikplats', 'next_Från_inkluderad'])\n",
    "\n",
    "# Step 7: Remove the final row in each sequence\n",
    "filtered_tcr_df = filtered_tcr_df.dropna(subset=['förbind_list']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep a copy\n",
    "tcr_df = filtered_tcr_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to update the identified_BdlNr given the förbind_list. So, if the förbind_list is in the dictionary (column Forbind), and the corresponding BdlNr is different then the current identified_BdlNr, then update it. Otherwise leave it as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Create a mapping from 'Forbind' to 'BdlNr' for quick lookups\n",
    "# forbind_to_bdl_map = dictionary_df.set_index('Forbind')['BdlNr'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Update 'identified_BdlNr' based on 'förbind_list'\n",
    "# def update_bandel(row):\n",
    "#     # Check if 'förbind_list' exists in the dictionary\n",
    "#     if row['förbind_list'] in forbind_to_bdl_map:\n",
    "#         new_bdl_nr = forbind_to_bdl_map[row['förbind_list']]\n",
    "#         # Update only if the new BdlNr is different\n",
    "#         if new_bdl_nr != row['identified_BdlNr']:\n",
    "#             return new_bdl_nr\n",
    "    \n",
    "#     # If not found, try the inverted link\n",
    "#     inverted_link = '-'.join(reversed(row['förbind_list'].split('-')))\n",
    "#     if inverted_link in forbind_to_bdl_map:\n",
    "#         new_bdl_nr = forbind_to_bdl_map[inverted_link]\n",
    "#         # Update only if the new BdlNr is different\n",
    "#         if new_bdl_nr != row['identified_BdlNr']:\n",
    "#             return new_bdl_nr\n",
    "    \n",
    "#     # If no update is needed or not found, return the current value\n",
    "#     return row['identified_BdlNr']\n",
    "\n",
    "# # Apply the function to update 'identified_BdlNr'\n",
    "# tcr_df['identified_BdlNr'] = tcr_df.apply(update_bandel, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, once we have identified BdlNR, we can use servicekontrakt_df to add a column with Kontraktsområdesnamn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the contract map with float conversion\n",
    "contract_map = servicekontrakt_df_T23.drop_duplicates(subset=['Bandelnr']).copy()\n",
    "contract_map['Bandelnr'] = contract_map['Bandelnr'].astype(float)\n",
    "contract_map = contract_map.set_index('Bandelnr')['Kontraktsområdesnamn'].to_dict()\n",
    "\n",
    "# Map with the contract map\n",
    "tcr_df['identified_BdlNr'] = tcr_df['identified_BdlNr'].astype(float)\n",
    "tcr_df['Kontraktsområdesnamn'] = tcr_df['identified_BdlNr'].map(contract_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also include a similar column with contract name, this one is based on BIS file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional mapping using the bandel_contract_dict\n",
    "tcr_df['kontrakt_från_bandel'] = tcr_df['identified_BdlNr'].map(bandel_contract_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No that we have identified BdlNr, we want to get the total length langd (which is in meter) of the Från trafikplats  and put it in a column (sum_langd). The idea is to use the order of forbind_list and look for the corresponding rows in dictionary_df (within same bandelnr = identified BdlNr) and accumulate the lenght in column dictionary_df(Banlangd). The forbind_list are normally linked, e.g., A-B, B-C, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to create the 'sum_langd' column for tcr_df\n",
    "# tcr_df['sum_langd'] = tcr_df.apply(\n",
    "#     lambda row: calculate_sum_langd(\n",
    "#         row['förbind_list'], \n",
    "#         row['identified_BdlNr'], \n",
    "#         dictionary_df\n",
    "#     ), \n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "tcr_df['sum_langd'] = tcr_df.apply(\n",
    "    lambda row: calculate_sum_langd_for_bandelnamn(row, dictionary_df),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any rows in tcr_df where sum_langd is None, print them\n",
    "print(tcr_df[tcr_df['sum_langd'].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
